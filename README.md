# DocuChat - Copiloto Conversacional sobre Documentos

Aplicaci√≥n desarrollada para el desaf√≠o t√©cnico de CatchAI que permite conversar inteligentemente con hasta 5 documentos PDF mediante RAG.

## Instalaci√≥n y Ejecuci√≥n

### Requisitos Previos
- Docker y Docker Compose instalados
- API Key de Google Gemini ([Obtener aqu√≠](https://aistudio.google.com/app/apikey))

### Ejecuci√≥n con Docker
```bash
docker-compose up --build
```

La aplicaci√≥n estar√° disponible en: http://localhost:8501

## Arquitectura del Sistema

![Arquitectura](/arquitectura.svg)

### Componentes Principales:

1. **Frontend**: Streamlit para interfaz conversacional
2. **Orquestaci√≥n**: LangChain para manejo de cadenas RAG
3. **Vector Store**: ChromaDB para almacenamiento de embeddings
4. **Embeddings**: Google Gemini Embeddings
5. **LLM**: Google Gemini 2.5 Flash

## ‚öôÔ∏è Justificaci√≥n de Elecciones T√©cnicas

### LangChain
- **Ventaja**: Ecosistema maduro para aplicaciones LLM
- **Funcionalidad**: Chains pre-construidas para RAG
- **Escalabilidad**: F√°cil integraci√≥n con diferentes LLMs

### ChromaDB
- **Simplicidad**: Base de datos vectorial ligera
- **Performance**: B√∫squeda r√°pida de similitudes
- **Memoria**: Gesti√≥n autom√°tica de colecciones

### Google Gemini
- **Costo-efectivo**: Tier gratuito generoso
- **Multimodal**: Capacidad de procesar texto y PDFs
- **Calidad**: Respuestas coherentes y contextuales

### Streamlit
- **Rapidez de desarrollo**: Prototipado r√°pido
- **Interactividad**: Componentes reactivos nativos
- **Deployment**: F√°cil despliegue y compartir

## üîÑ Flujo Conversacional

1. **Carga de Documentos**:
   ```
   PDF Upload ‚Üí PyPDFLoader ‚Üí Text Splitting ‚Üí Embeddings ‚Üí ChromaDB
   ```

2. **Procesamiento de Query**:
   ```
   User Question ‚Üí History-Aware Retriever ‚Üí Context Retrieval ‚Üí LLM Response
   ```

3. **RAG Pipeline**:
   ```
   Query + History ‚Üí Retrieval Chain ‚Üí Document Chunks ‚Üí Prompt Template ‚Üí LLM ‚Üí Response
   ```

## ‚ú® Funcionalidades Implementadas

### Requisitos M√≠nimos ‚úÖ
- [x] Subida de hasta 5 PDFs
- [x] Extracci√≥n y vectorizaci√≥n de contenido  
- [x] Interfaz conversacional
- [x] Orquestaci√≥n estructurada con LangChain

### Funcionalidades Opcionales ‚úÖ
- [x] **Resumen autom√°tico** de documentos cargados
- [x] **Comparaci√≥n inteligente** entre m√∫ltiples documentos
- [x] **Clasificaci√≥n por temas** y an√°lisis tem√°tico
- [x] **Historial conversacional** con context-awareness
- [x] **Gesti√≥n de memoria** para optimizaci√≥n de rendimiento

### Par√°metros Configurables
- **Chunk Size**: 5000 caracteres (optimizado para PDFs)
- **Chunk Overlap**: 1000 caracteres (preserva contexto)
- **Temperature**: 0.3 (balance creatividad/precisi√≥n)
- **Max Collections**: 20 (gesti√≥n de memoria)

## üöß Limitaciones Actuales

1. **Limite de Procesamiento**: La capa gratuita limita la velocidad de subida de archivos
2. **L√≠mite de archivos**: M√°ximo 5 PDFs simult√°neos
3. **Persistencia**: Base de datos en memoria (se resetea al reiniciar)
4. **Idioma**: Optimizado para espa√±ol
5. **Concurrencia**: Una sesi√≥n por instancia

## üó∫Ô∏è Roadmap y Mejoras Futuras

### Corto Plazo (1-2 semanas)
- [ ] Persistencia de base de datos vectorial
- [ ] Gemini API Key Tier 1 
- [ ] M√©tricas de calidad de respuestas
- [ ] Cach√© de embeddings para optimizaci√≥n

### Mediano Plazo (1-2 meses)  
- [ ] Autenticaci√≥n de usuarios
- [ ] M√∫ltiples sesiones concurrentes
- [ ] API REST para integraci√≥n externa
- [ ] Dashboard de analytics

### Largo Plazo (3+ meses)
- [ ] Multi-tenancy empresarial
- [ ] Integraci√≥n con bases de datos empresariales
- [ ] Soporte para documentos multimedia
- [ ] Fine-tuning de modelos espec√≠ficos

---

**Desarrollado por**: [Alex Tardon](https://github.com/AlexFT257)
**Fecha**: 13 Agosto 2025  
**Desaf√≠o**: CatchAI - Desarrollador/a Joven de IA